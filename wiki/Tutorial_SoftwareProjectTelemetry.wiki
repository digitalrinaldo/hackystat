#summary A tutorial on basic use of Software Project Telemetry

== 1.0 Motivation ==

Hackystat sensors provide a way to collect very low-level data about software processes and products. For example, a !DevEvent sensor data instance might indicate that a developer saved the file Foo.java at 11:59:59am on 2007-09-09.  Such low-level information, by itself, is very difficult to use in project management and decision making.   There needs to be a way to abstract this low-level data in such a way that it becomes meaningful.

This need for abstraction leads directly to the second problem:  which abstractions should be used?  After all, different organizations have different work processes, which means different abstractions will be meaningful to them.  One organization might be committed to the use of Test Driven Design practices, and so an abstraction that enables them to understand their compliance with TDD practices might be quite useful.  Another organization might not care about this abstraction.

Software Project Telemetry is an analysis mechanism for Hackystat that
provides one way of addressing both of these issues.  In order to make
low-level data useful for project management and decision making, it
supports the creation of trend lines that show how various characteristics
of software development are changing over time.  To support the work
practices of different organizations, it provides a domain specific
language that allows the creation of custom trend lines (called telemetry
"streams") and their visualization together in a specific telemetry
"chart".  

The goal of this introductory tutorial is to show how telemetry can be
visualized in Hackystat using the !TelemetryViewer application, and how
telemetry can reveal interesting characteristics of the software
development process.  To facilitate this presentation, will we present
"simulated" telemetry data, and use the pre-existing telemetry definitions
that come with the public distribution of Hackystat.  

== 2.0 The Telemetry Viewer application ==

The public telemetry viewer application is available at [http://dasha.ics.hawaii.edu:9875/telemetryviewer/].  You need to login to the !TelemetryViewer using your Hackystat user name and password.  Once you are logged in, you will see a screen similar to the following:

[http://hackystat.googlecode.com/svn/wiki/telemetry-devtime1.gif]

There are several things to observe about this screen:

  * Each !TelemetryViewer instance connects to a given Telemetry analysis service and a given !SensorBase service for its information.  This instance is configured to connect to the public Telemetry analysis and !SensorBase services. 

  * Each !TelemetryViewer instance allows you to specify what telemetry  to see using  a pull-down list of pre-defined charts. These charts are defined using the Software Project Telemetry domain specific language, and those definitions are read in from definition files at the time that the !TelemetryViewer starts up.  The details of defining custom charts are beyond the scope of this introductory tutorial.

  * To specify a telemetry chart to display, you specify a Project from a pull-down list that contains all of the Projects you are associated with as either an Owner or a Member.  You must also specify a time interval, either as an "absolute" time interval with a specific  start day and end day, or as a "relative" date whose end day is always the current day.  Finally, a given telemetry chart can be defined such that it requests additional parameters. These will also appear in the viewer, and they will always be prefilled with default values. 

Once you have specified the parameters, you press "Update" to see the telemetry chart.  Here is an example result:

[http://hackystat.googlecode.com/svn/wiki/telemetry-devtime2.gif]

This !DevTime telemetry chart is a very simple chart that displays only a single telemetry stream, called !DevTime.  !DevTime is a proxy for developer effort that is based upon analysis of DevEvent data.   The visualization is created using the [http://timepedia.org/chronoscope/ Timepedia Chronoscope] visualization platform for time series data sets.  This platform provides a great deal of capability that we are just beginning to explore, but you will already be able to appreciate the ability to pan back and forth and zoom in and out of the dataset using the arrow keys.   

||Important note:  At the time of writing of this documentation (January, 2008), Chronoscope workes with Firefox 1.5-2.0, Safari, and Opera (mostly).  It does not yet support Internet Explorer. ||

While a single trend line is kind of cool for a minute or two, it does not illustrate how Software Project Telemetry can be used in project management and decision making.  For that, it is generally necessary to look at a set of telemetry streams and notice important changes in their values.  The next section shows how this works with a simulated data set. 

== 3.0 Understanding project characteristics through Telemetry: A simulated example ==

The Simple Telemetry scenario is designed to illustrate how Software
Project Telemetry can reveal various characteristics of an ongoing software
development project.

The Simple Telemetry scenario consists of four 10 day periods of simulated
project data during July 2007.

Each 10 day period of development can be thought of as a Scrum
"sprint". While real software projects typically have sprint durations
longer than 10 days, this approach helps provide the most inutitive
understanding of how software project telemetry can be applied in an agile
context.

This Simple Telemetry scenario involves two developers, Joe and Bob, who
are working together on a project called !SimpleTelemetry. Their Hackystat
usernames are joe.simpletelemetry@hackystat.org and
bob.simpletelemetry@hackystat.org.

The scenario involves two kinds of charts: product-oriented charts that
focus on trends in the project as a whole, and member-oriented charts that
focus on the activities of individual members in the project. The
!ProductDevTrends and ProductQATrends telemetry charts show trends in
coverage, size, churn, commits, builds, test invocations, code issues, and
!DevTime for the project as a whole. The !MemberTrends chart shows, for a
single developer, their trends in test invocations, DevTime, builds,
commits, and churn.

The telemetry for the four simulated sprints illustrates the following
development scenarios:

    * "Healthy Development" (Sprint 1, July 2-11, 2007). This first sprint shows what telemetry looks like in an idealized, healthy project development scenario. Coverage is consistently high; overall code size changes smoothly; Churn and Code Issues are low relative to code size; Commits, Builds, and Unit tests occur regularly; and DevTime is consistent, and at a "Goldilocks" level (not too high, not too low.) 

    * "Late Start" (Sprint 2, July 12-21, 2007). This sprint shows how telemetry can reveal a late start and its potential impact. For the first half of the sprint, there is very little movement on the project. Then all of the indicators (DevTime, Churn, Commits, Size) show a dramatic spike upward. However, the negative impact of the late start manifests itself in quality: coverage is low, and code issues are high. 

    * "Design Trouble" (Sprint 3, July 22-31, 2007). This sprint shows how telemetry can provide an early warning signal. The telemetry shows decreasing coverage, increasing code issues, and high levels of churn. If a project has been generating telemetry similar to Sprint 1 and then shifts to these trends, it indicates that something fundamental about the project has changed, either in personnel, requirements, or management. 

    * "Resource mismanagement" (Sprint 4, August 1-10, 2007). This sprint shows how telemetry can reveal unbalanced resource allocation. The telemetry shows that Joe is overworked and taking on too much of the project development burden, while Bob is essentially idle. 


=== 3.1 Sprint 1: Healthy Development ===

Let's begin with telemetry for a "healthy" project.  Here is the ProductQATrends telemetry chart for the time period associated with the first sprint: 

[http://hackystat.googlecode.com/svn/wiki/telemetry-qa-sprint1.75.gif]

As you can see, coverage is above 90%, unit tests are invoked consistently every day around 10 times, and code issues are quite low. 

The !ProductDevTrends for a "healthy" project show similar consistency:

[http://hackystat.googlecode.com/svn/wiki/telemetry-dev-sprint1.75.gif]

Churn, Commits, Builds, and DevTime hours are fairly stable.  The only line trending upward is the total code size, which is growing almost linearly.  (Of course, a project can be "healthy" with a non-linear, or even decreasing code size, but it is important that the other metrics show a certain level of stability in a healthy project.)

Finally, we can take a look at the !MemberTrends chart to get a perspective on the development behavior of individual developers.  Here's Joe's !MemberTrends chart:

[http://hackystat.googlecode.com/svn/wiki/telemetry-member-joe-sprint1.75.gif]

Joe's individual telemetry is quite similar to the project as a whole: all of the indicator are stable and within reasonable values. 
=== 3.1 Sprint 2: Late start ===

Now let's look at the telemetry for a scenario where a project gets a late start and then the developers try to play "catch up".  Let's start this time with the !ProductDevTrends chart:

[http://hackystat.googlecode.com/svn/wiki/telemetry-dev-sprint2.75.gif]

Here you can see that there are very low levels of project activity for the first half of the sprint, and then frenetic activity for the last five days. 

The !ProductQATrends chart is quite revealing:

[http://hackystat.googlecode.com/svn/wiki/telemetry-qa-sprint2.75.gif]

You can see that the coverage is much lower than what we observed for the "healthy" project, and the number of code issues is much higher. 
























